---
title: Updated Ensemble Model
author: Avi Agarwal
date: '2024-10-28'
slug: updated-ensemble-model
categories: []
tags: []
---
```{r , echo= FALSE, message = FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
library(sjPlot)
library(plotly)
library(maps)
library(car)
library(CVXR)
set.seed(02138)

```



```{r , echo= FALSE, message = FALSE, warning=FALSE}
swing_state_polls <- read_csv("state_polls_1968-2024.csv")
swing_states <- c("Florida", "Arizona", "Georgia", "Michigan", "Nevada", "North Carolina", "Pennsylvania", "Wisconsin")
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}

swing_state_polls_dem <- swing_state_polls |>
  filter(state %in% swing_states & weeks_left < 13 & weeks_left >= 3 & party == "DEM") |>
  group_by(state, year,  weeks_left) |>
  summarize(avg = mean(poll_support)) |>
  ungroup() |>
  pivot_wider(names_from = weeks_left, values_from = avg) |>
  mutate(polling_trend_7_3 = `3` - `7`,
         polling_trend_12_8 = `8` - `12`,
         average_polling = rowMeans(across(`3`:`12`)),
         current_week = `3`) |>
  na.omit() |>
  select(year, state, polling_trend_7_3, polling_trend_12_8, average_polling, current_week)
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
state_dpi <- read_csv("Table.csv") 
state_dpi[, 28:77] <- lapply(state_dpi[, 28:77], as.numeric)
state_dpi <- state_dpi %>% select(-c(3:27))
state_dpi <- state_dpi |> 
  mutate(state = GeoName) |>
  select(-GeoName, -GeoFips) 

```

```{r , echo= FALSE, message = FALSE, warning=FALSE}

swing_state_dpi <- state_dpi |>
  filter(state %in% swing_states) |>
  pivot_longer(cols = `1974`:`2023`, names_to = "year", values_to = "percent_change_dpi") |>
  mutate(year = as.numeric(year)) |>
  mutate(election_year = year + 1) |>
  filter(election_year %% 4 == 0) |>
  select(-year) |>
  rename(year = election_year) 
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
yearly_inflation <- read_csv("yearly_inflation.csv")
yearly_inflation <- yearly_inflation |> 
  select(-c(1:4)) |>
  pivot_longer(cols = 1:64, names_to = "year", values_to = "yearly_national_inflation")

```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
yearly_inflation <- yearly_inflation |> 
  mutate(year = as.numeric(year)) |>
  mutate(year = year + 1) |>
  mutate(yearly_national_inflation = as.numeric(yearly_national_inflation)) 
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
swing_state_dpi<- swing_state_dpi |>
  left_join(yearly_inflation, by = "year") |>
  mutate(dpi_inflation_adjusted = percent_change_dpi - yearly_national_inflation) |>
  select(-percent_change_dpi, -yearly_national_inflation)
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
swing_state_data <- swing_state_polls_dem |>
  left_join(swing_state_dpi, by = c("year","state")) |>
  na.omit()
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
state_pop_vote <- read_csv("state_popvote_1948_2020.csv") 
state_pop_vote_dem <- state_pop_vote |>
  filter(state %in% swing_states) |>
  select(c( year, state,D_pv2p, D_pv2p_lag1, D_pv2p_lag2)) 

  
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
swing_state_data <- swing_state_data |>
  left_join(state_pop_vote_dem, by = c("year", "state"))
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
nat_pop_vote <- read_csv("popvote_1948_2020.csv") |>
  filter(party == "democrat") |> 
  select(year, incumbent_party) |>
  mutate(incumbent_party = ifelse(incumbent_party == TRUE, 1, 0))
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
swing_state_data <- swing_state_data |>
  left_join(nat_pop_vote, by = "year")
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
fred_econ <- read_csv("fred_econ.csv") 
fred_adjusted <- fred_econ |>
  filter(year > 1958) |>
  mutate(unemployment_growth_quarterly = (unemployment - lag(unemployment, 1)) / lag(unemployment, 1) * 100) |>
  filter(quarter == 2) |>
  mutate(sp500_growth_quarterly = ((sp500_adj_close - sp500_open)) / sp500_open * 100) |>
  filter(year >= 1960)
         
data_2020 <- fred_adjusted |>
  filter(year == 2020 | year == 2019) |>
  mutate(RDPI_growth_quarterly =  lag(RDPI_growth_quarterly, 1), unemployment_growth_quarterly =  lag(unemployment_growth_quarterly, 1)) |>
  filter(year == 2020)

fred_adjusted <- fred_adjusted |>
  filter(year != 2020) |>
  bind_rows(data_2020) |>
  filter(year %% 4 == 0) |>
  select(year, RDPI_growth_quarterly, unemployment_growth_quarterly) 

```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
 swing_state_data <-  swing_state_data |>
  left_join(fred_adjusted, by = "year")
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
swing_state_data_train <- swing_state_data |>
  filter(year < 2016)

swing_state_data_true <- swing_state_data |> 
  filter(year == 2016)
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
twentyfour_lags <- state_pop_vote |>
  filter(year == 2020) |>
   mutate(D_pv2p_lag2= D_pv2p_lag1,
     D_pv2p_lag1 = D_pv2p,
     year = 2024) |>
  select(-D_pv2p)

swing_state_data_test <- swing_state_data |>
  filter(year == 2024) |>
  select(where(~ !all(is.na(.)))) |>
  left_join(twentyfour_lags, by = c("state", "year")) 
```



```{r , echo= FALSE, message = FALSE, warning=FALSE}

swing_states <- c("Arizona", "Georgia", "Michigan", "Nevada", "North Carolina", "Pennsylvania", "Wisconsin")

state_weights <- list()
predictions_2024 <- list()

c <- 3  

# Loop through each swing state to create models, make predictions, and perform constrained regression
for (i in swing_states) { #used GPT to help write this function
 # print(i)
  
  # Filter the training data to include only Florida and the target swing state
  state_train_data <- swing_state_data_train |> 
    mutate(state = ifelse(state == "Florida", "AAFlorida", state)) |>
    filter(state == "AAFlorida" | state == i)
  
  # Use only the specific swing state in the test data (exclude Florida from test predictions)
  state_test_data <- swing_state_data_true |> 
    mutate(state = ifelse(state == "Florida", "AAFlorida", state)) |>
    filter(state == "AAFlorida" | state == i)
  
  # Create models for the current state using Florida as the intercept in the training data
  mod_1 <- lm(
    data = state_train_data, 
    D_pv2p ~ state + D_pv2p_lag1 + incumbent_party + RDPI_growth_quarterly
  )
  
  mod_2 <- lm(
    data = state_train_data, 
    D_pv2p ~ state + polling_trend_7_3 + polling_trend_12_8 + current_week
  )
  
  mod_3 <- lm(
    data = state_train_data, 
    D_pv2p ~ state + polling_trend_7_3 + polling_trend_12_8 + D_pv2p_lag1 + 
      D_pv2p_lag2 + current_week + incumbent_party + unemployment_growth_quarterly + dpi_inflation_adjusted
  )
  
  # Generate predictions for the current state using the three models
  pred_1 <- as.numeric(predict(mod_1, newdata = state_test_data))
  pred_2 <- as.numeric(predict(mod_2, newdata = state_test_data))
  pred_3 <- as.numeric(predict(mod_3, newdata = state_test_data))
  
  # Combine predictions into a matrix for the constrained regression
  predictions <- cbind(pred_1, pred_2, pred_3)

  # Target variable for the current state
  y_test <- state_test_data$D_pv2p 
  
  # Initial unconstrained regression to get starting weights
  w <- lm(y_test ~ predictions - 1)
  initial_weights <- coef(w)
  
  # Set up constrained regression
  beta <- Variable(c)
  
  # Define objective to minimize sum of squares
  objective <- Minimize(sum_squares(y_test - predictions %*% beta))
  
  # Define problem with constraints
  prob <- Problem(objective)
  constraints(prob) <- list(beta >= 0, beta <= 1)

  
  # Solve the constrained regression problem
  solution_prob <- solve(prob)
  
  # Get the optimized weights for the current state
  weights_dem <- solution_prob$getValue(beta)
  
  # Store the weights in the list

  state_weights[[i]] <- weights_dem
  
#  print(sum(state_weights[[i]]))
  
  state_test_data_2024 <- swing_state_data_test |> 
    mutate(state = ifelse(state == "Florida", "AAFlorida", state)) |>
    filter(state == "AAFlorida" | state == i)
  
  # Generate predictions for the current state using the three models with 2024 data
  pred_1_2024 <- as.numeric(predict(mod_1, newdata = state_test_data_2024))
  pred_2_2024 <- as.numeric(predict(mod_2, newdata = state_test_data_2024))
  pred_3_2024 <- as.numeric(predict(mod_3, newdata = state_test_data_2024))
  
    # Combine predictions into a matrix for the constrained regression
  predictions_matrix_2024 <- cbind(pred_1_2024, pred_2_2024, pred_3_2024)
 # print(predictions_matrix_2024)
  
  # Retrieve the weights for the current state
  weights_dem <- state_weights[[i]]
  
  prediction_2024 <- as.vector(predictions_matrix_2024[2, ] %*% weights_dem)
  #prediction_2024_fl <- predictions_matrix_2024 %*% weights_dem

  #print(prediction_2024_fl)
  
  # Store the prediction in a list with the state name
  predictions_2024[[i]] <- data.frame(state = i, prediction_2024 = prediction_2024)
}

predictions_2024_df <- do.call(rbind, predictions_2024)
#predictions_2024_df

```

```{r , echo= FALSE, message = FALSE, warning=FALSE}

# List to store the MSE for each state
mse_results <- list()

swing_states <- c("Arizona", "Georgia", "Michigan", "Nevada", "North Carolina", "Pennsylvania", "Wisconsin")


# Loop through each swing state
for (i in swing_states) {
  

  
   # Filter the training data to include only Florida and the target swing state
  state_train_data <- swing_state_data_train |> 
    mutate(state = ifelse(state == "Florida", "AAFlorida", state)) |>
    filter(state == "AAFlorida" | state == i)
  
  # Use only the specific swing state in the test data (exclude Florida from test predictions)
  state_test_data <- swing_state_data_true |> 
    mutate(state = ifelse(state == "Florida", "AAFlorida", state)) |>
    filter(state == "AAFlorida" | state == i)
  

  # Filter the test data for 2020, including only Florida and the target swing state
  state_test_data_2020 <- swing_state_data_true |>
    mutate(state = ifelse(state == "Florida", "AAFlorida", state)) |>
    filter(state == "AAFlorida" | state == i)
  

  mod_1 <- lm(
    data = state_train_data, 
    D_pv2p ~ state + D_pv2p_lag1 + incumbent_party + RDPI_growth_quarterly
  )
  
  mod_2 <- lm(
    data = state_train_data, 
    D_pv2p ~ state + polling_trend_7_3 + polling_trend_12_8 + current_week
  )
  
  mod_3 <- lm(
    data = state_train_data, 
    D_pv2p ~ state + polling_trend_7_3 + polling_trend_12_8 + D_pv2p_lag1 + 
      D_pv2p_lag2 + current_week + incumbent_party + unemployment_growth_quarterly + dpi_inflation_adjusted
  )
  

  pred_1 <- as.numeric(predict(mod_1, newdata = state_test_data_2020))
  pred_2 <- as.numeric(predict(mod_2, newdata = state_test_data_2020))
  pred_3 <- as.numeric(predict(mod_3, newdata = state_test_data_2020))
  
  
  # Combine predictions for constrained regression (Democratic model)
  predictions <- cbind(pred_1[2], pred_2[2], pred_3[2])
  weights_dem <- state_weights[[i]] # Retrieve weights for Democratic model
  
  # Calculate Democratic prediction as weighted sum of model predictions
  prediction_dem <- as.vector(predictions %*% weights_dem)
  
  
    state_test_data_2020 <- swing_state_data_true |>
    filter( state == i)
  
  # Calculate MSE for Democratic prediction
  mse_dem <- mean((state_test_data_2020$D_pv2p - prediction_dem)^2)

  
  mse_results[[i]] <- data.frame(
    state = i,
    mse_dem = mse_dem
  )
  
  
}

mse_results_df <- do.call(rbind, mse_results)


in_MSE <- tab_df(
  mse_results_df,
  title = "In-Sample MSE for Democratic Predictions by Swing State (2016 Data)",
  digits = 4,                # Rounds MSE values to four decimal places
  show.rownames = FALSE,      # Hides row numbers for a cleaner look
  CSS = list(css.table = "width: 60%;", css.caption = "font-weight: bold; text-align: center;")
)


```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
# List to store the MSE for each state
mse_results <- list()

swing_states <- c("Arizona", "Georgia", "Michigan", "Nevada", "North Carolina", "Pennsylvania", "Wisconsin")




# Loop through each swing state
for (i in swing_states) {
  swing_state_data_true <- swing_state_data |> 
  filter(year == 2020)
  
  

  
   # Filter the training data to include only Florida and the target swing state
  state_train_data <- swing_state_data_train |> 
    mutate(state = ifelse(state == "Florida", "AAFlorida", state)) |>
    filter(state == "AAFlorida" | state == i)
  
  # Use only the specific swing state in the test data (exclude Florida from test predictions)
  state_test_data <- swing_state_data_true |> 
    mutate(state = ifelse(state == "Florida", "AAFlorida", state)) |>
    filter(state == "AAFlorida" | state == i)
  

  # Filter the test data for 2020, including only Florida and the target swing state
  state_test_data_2020 <- swing_state_data_true |>
    mutate(state = ifelse(state == "Florida", "AAFlorida", state)) |>
    filter(state == "AAFlorida" | state == i)
  

  mod_1 <- lm(
    data = state_train_data, 
    D_pv2p ~ state + D_pv2p_lag1 + incumbent_party + RDPI_growth_quarterly
  )
  
  mod_2 <- lm(
    data = state_train_data, 
    D_pv2p ~ state + polling_trend_7_3 + polling_trend_12_8 + current_week
  )
  
  mod_3 <- lm(
    data = state_train_data, 
    D_pv2p ~ state + polling_trend_7_3 + polling_trend_12_8 + D_pv2p_lag1 + 
      D_pv2p_lag2 + current_week + incumbent_party + unemployment_growth_quarterly + dpi_inflation_adjusted
  )
  

  pred_1 <- as.numeric(predict(mod_1, newdata = state_test_data_2020))
  pred_2 <- as.numeric(predict(mod_2, newdata = state_test_data_2020))
  pred_3 <- as.numeric(predict(mod_3, newdata = state_test_data_2020))
  
  
  # Combine predictions for constrained regression (Democratic model)
  predictions <- cbind(pred_1[2], pred_2[2], pred_3[2])
  weights_dem <- state_weights[[i]] # Retrieve weights for Democratic model
  
  # Calculate Democratic prediction as weighted sum of model predictions
  prediction_dem <- as.vector(predictions %*% weights_dem)
  

    state_test_data_2020 <- swing_state_data_true |>
    filter( state == i)
  
  # Calculate MSE for Democratic prediction
  mse_dem <- mean((state_test_data_2020$D_pv2p - prediction_dem)^2)
  

  
  mse_results[[i]] <- data.frame(
    state = i,
    mse_dem = mse_dem
  )
  
  
}

# Combine the MSE results into a single data frame
mse_results_df <- do.call(rbind, mse_results)


out_MSE <- tab_df(
  mse_results_df,
  title = "Out-of-Sample MSE for Democratic Predictions by Swing State (2020 Data)",
  digits = 4,                # Rounds MSE values to four decimal places
  show.rownames = FALSE,      # Hides row numbers for a cleaner look
  CSS = list(css.table = "width: 60%;", css.caption = "font-weight: bold; text-align: center;")
)
```


```{r , echo= FALSE, message = FALSE, warning=FALSE}
swing_states <- c("Florida", "Arizona", "Georgia", "Michigan", "Nevada", "North Carolina", "Pennsylvania", "Wisconsin")

swing_state_polls_rep <- swing_state_polls |>
  filter(state %in% swing_states & weeks_left < 13 & weeks_left >= 3 & party == "REP") |>
  group_by(state, year, weeks_left) |>
  summarize(avg = mean(poll_support)) |>
  ungroup() |>
  pivot_wider(names_from = weeks_left, values_from = avg) |>
  mutate(polling_trend_7_3 = `3` - `7`,
         polling_trend_12_8 = `8` - `12`,
         average_polling = rowMeans(across(`3`:`12`)),
         current_week = `3`) |>
  na.omit() |>
  select(year, state, polling_trend_7_3, polling_trend_12_8, average_polling, current_week)

swing_state_dpi_rep <- state_dpi |>
  filter(state %in% swing_states) |>
  pivot_longer(cols = `1974`:`2023`, names_to = "year", values_to = "percent_change_dpi") |>
  mutate(year = as.numeric(year)) |>
  mutate(election_year = year + 1) |>
  filter(election_year %% 4 == 0) |>
  select(-year) |>
  rename(year = election_year) 

yearly_inflation <- yearly_inflation |>
  mutate(year = as.numeric(year)) |>
  mutate(year = year + 1) |>
  mutate(yearly_national_inflation = as.numeric(yearly_national_inflation)) 

swing_state_dpi_rep <- swing_state_dpi_rep |>
  left_join(yearly_inflation, by = "year") |>
  mutate(dpi_inflation_adjusted = percent_change_dpi - yearly_national_inflation) |>
  select(-percent_change_dpi, -yearly_national_inflation)

nat_pop_vote_rep <- read_csv("popvote_1948_2020.csv") |>
  filter(party == "republican") |> 
  select(year, incumbent_party) |>
  mutate(incumbent_party = ifelse(incumbent_party == TRUE, 1, 0))

swing_state_data_rep <- swing_state_polls_rep |>
  left_join(swing_state_dpi_rep, by = c("year","state")) |>
  na.omit()

state_pop_vote_rep <- state_pop_vote |>
  filter(state %in% swing_states) |>
  select(c(year, state, R_pv2p, R_pv2p_lag1, R_pv2p_lag2 ))

swing_state_data_rep <- swing_state_data_rep |>
  left_join(state_pop_vote_rep, by = c("year", "state"))

swing_state_data_rep <- swing_state_data_rep |>
  left_join(fred_adjusted, by = "year")

swing_state_data_rep <- swing_state_data_rep |>
  left_join(nat_pop_vote_rep, by = "year")


swing_state_data_train_rep <- swing_state_data_rep |>
  filter(year < 2016)

swing_state_data_true_rep <- swing_state_data_rep |>
  filter(year == 2016)

twentyfour_lags_rep <- state_pop_vote_rep |>
  filter(year == 2020) |>
  mutate(R_pv2p_lag2 = R_pv2p_lag1,
         R_pv2p_lag1 = R_pv2p,
         year = 2024) |>
  select(-R_pv2p)

swing_state_data_test_rep <- swing_state_data_rep |>
  filter(year == 2024) |>
  select(where(~ !all(is.na(.)))) |>
  left_join(twentyfour_lags_rep, by = c("state", "year"))

```


```{r , echo= FALSE, message = FALSE, warning=FALSE}

swing_states <- c("Arizona", "Georgia", "Michigan", "Nevada", "North Carolina", "Pennsylvania", "Wisconsin")

state_weights_rep <- list()

predictions_2024_rep <- list()

for (i in swing_states) {
 # print(i)
  
  state_train_data_rep <- swing_state_data_train_rep |> 
    mutate(state = ifelse(state == "Florida", "AAFlorida", state)) |>
    filter(state == "AAFlorida" | state == i)
  
  state_test_data_rep <- swing_state_data_true_rep |> 
    mutate(state = ifelse(state == "Florida", "AAFlorida", state)) |>
    filter(state == "AAFlorida" | state == i)
  
  mod_1_rep <- lm(
    data = state_train_data_rep, 
    R_pv2p ~ state + R_pv2p_lag1  + incumbent_party + RDPI_growth_quarterly
  )
  
  mod_2_rep <- lm(
    data = state_train_data_rep, 
    R_pv2p ~ state + polling_trend_7_3 + polling_trend_12_8 + current_week
  )
  
  mod_3_rep <- lm(
    data = state_train_data_rep, 
    R_pv2p ~ state + polling_trend_7_3 + polling_trend_12_8 + R_pv2p_lag1 + current_week + incumbent_party + unemployment_growth_quarterly + dpi_inflation_adjusted)
  
  pred_1_rep <- as.numeric(predict(mod_1_rep, newdata = state_test_data_rep))
  pred_2_rep <- as.numeric(predict(mod_2_rep, newdata = state_test_data_rep))
  pred_3_rep <- as.numeric(predict(mod_3_rep, newdata = state_test_data_rep))

  
  predictions_rep <- cbind(pred_1_rep, pred_2_rep, pred_3_rep)
  
  y_test_rep <- state_test_data_rep$R_pv2p 
  
  w_rep <- lm(y_test_rep ~ predictions_rep - 1)
  initial_weights_rep <- coef(w_rep)
  
  beta_rep <- Variable(c)
  
  objective_rep <- Minimize(sum_squares(y_test_rep - predictions_rep %*% beta_rep))
  
  
  
  prob_rep <- Problem(objective_rep)
  constraints(prob_rep) <- list(beta_rep >= 0, beta_rep <= 1)

  
  solution_prob_rep <- solve(prob_rep)
  
  weights_rep <- solution_prob_rep$getValue(beta_rep)
  
  state_weights_rep[[i]] <- weights_rep
  
  #print(weights_rep)
 # print(sum(state_weights_rep[[i]]))
  
  state_test_data_2024_rep <- swing_state_data_test_rep |> 
    mutate(state = ifelse(state == "Florida", "AAFlorida", state)) |>
    filter(state == "AAFlorida" | state == i)
  
  pred_1_2024_rep <- as.numeric(predict(mod_1_rep, newdata = state_test_data_2024_rep))
  pred_2_2024_rep <- as.numeric(predict(mod_2_rep, newdata = state_test_data_2024_rep))
  pred_3_2024_rep <- as.numeric(predict(mod_3_rep, newdata = state_test_data_2024_rep))

  
  predictions_matrix_2024_rep <- cbind(pred_1_2024_rep, pred_2_2024_rep, pred_3_2024_rep)
  
  weights_rep <- state_weights_rep[[i]]

  prediction_2024_rep <- as.vector(predictions_matrix_2024_rep[2, ] %*% weights_rep)
  #prediction_2024_fl <- predictions_matrix_2024 %*% weights_dem


  
  predictions_2024_rep[[i]] <- data.frame(state = i, prediction_2024_rep = prediction_2024_rep)
}

predictions_2024_df_rep <- do.call(rbind, predictions_2024_rep)
#predictions_2024_df_rep


```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
ensemble_pred <- predictions_2024_df |>
  left_join(predictions_2024_df_rep, by = "state") |>
  mutate(adj_dem_vote = prediction_2024/(prediction_2024 + prediction_2024_rep) *100,
         adj_rep_vote = prediction_2024_rep/(prediction_2024 + prediction_2024_rep) *100,
         margin = adj_dem_vote - adj_rep_vote,
         sum = adj_dem_vote + adj_rep_vote) |>
  filter(state %in% swing_states) |>
  select(state, adj_dem_vote, adj_rep_vote, margin) 

e_pred<- tab_df(
  ensemble_pred,
  title = "Ensemble Model Predicted Vote Share",
  digits = 2,              # Rounds values to 2 decimal places
  show.rownames = FALSE,    # Hides row names for cleaner look
  CSS = list(css.table = "width: 50%;", css.caption = "font-weight: bold; text-align: center;")
)
```


```{r , echo= FALSE, message = FALSE, warning=FALSE}
swing_state_data_dems <- ensemble_pred %>%
  mutate(state = tolower(state))

us_states <- map_data("state")

swing_map_data <- us_states %>%
  left_join(swing_state_data_dems, by = c("region" = "state"))


map <- ggplot(data = swing_map_data, aes(x = long, y = lat, group = group, fill = margin)) +
  geom_polygon(color = "white") +
  scale_fill_gradient2(low = "darkred", mid = "white", high = "darkblue", midpoint = 0, 
                       name = "Dem. Voting Margin (%)") +
  theme_minimal() +
  coord_fixed(1.3) +
  labs(title = "2024 Swing State Voting Margins",
       subtitle = "Shaded by predicted Democratic (blue) or Republican (red) vote margins") +
  theme(
    axis.line = element_blank(),        
    axis.text = element_blank(),       
    axis.ticks = element_blank(),      
    axis.title = element_blank(),      
    panel.grid = element_blank()     
  )
```


```{r , echo= FALSE, message = FALSE, warning=FALSE}
b_train_data <- swing_state_data_train |> 
    mutate(state = ifelse(state == "Florida", "AAFlorida", state)) 

b_model <- lm(
  data = b_train_data, 
  D_pv2p ~ +
    polling_trend_7_3 +
    polling_trend_12_8 +
    D_pv2p_lag1 +
    current_week + 
    incumbent_party +
    dpi_inflation_adjusted +
    unemployment_growth_quarterly + state) 

swing_state_data_test <- swing_state_data_test |>
  mutate(state = ifelse(state == "Florida", "AAFlorida", state))

b_model_predictions <- predict(b_model, swing_state_data_test, interval = "prediction")

b_model_predictions <- as.data.frame(b_model_predictions)


pred_b_model <- data.frame(
  state = as.character(swing_state_data_test$state),  # Convert to character to ensure names
  year = swing_state_data_test_rep$year,
  Prediction = b_model_predictions$fit
)





``` 

```{r , echo= FALSE, message = FALSE, warning=FALSE}

b_train_data_rep <- swing_state_data_train_rep |> 
    mutate(state = ifelse(state == "Florida", "AAFlorida", state)) 

b_model_rep <- lm(
  data = b_train_data_rep, 
  R_pv2p ~ +
    polling_trend_7_3 +
    polling_trend_12_8 +
    R_pv2p_lag1 +
    current_week + 
    incumbent_party +
    dpi_inflation_adjusted +
    unemployment_growth_quarterly + state) 

swing_state_data_test_rep <- swing_state_data_test_rep |>
  mutate(state = ifelse(state == "Florida", "AAFlorida", state))

b_model_predictions_rep <- predict(b_model_rep, swing_state_data_test_rep, interval = "prediction")

b_model_predictions_rep <- as.data.frame(b_model_predictions_rep)



pred_b_model_rep <- data.frame(
  state = as.character(swing_state_data_test$state),  # Convert to character to ensure names
  year = swing_state_data_test_rep$year,
  Prediction = b_model_predictions_rep$fit
)


```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
ensemble_pred_b <- pred_b_model |>
  left_join(pred_b_model_rep, by = "state") |>
  mutate(adj_dem_vote = Prediction.x/(Prediction.x + Prediction.y) *100,
         adj_rep_vote = Prediction.y/(Prediction.y + Prediction.x) *100,
         margin = adj_dem_vote - adj_rep_vote,
         sum = adj_dem_vote + adj_rep_vote) |>
  filter(state %in% swing_states) |>
  select(state, adj_dem_vote, adj_rep_vote, margin)

lm_pred <- tab_df(
  ensemble_pred_b,
  title = "LM Model Predicted Vote Share",
  digits = 2,              # Rounds values to 2 decimal places
  show.rownames = FALSE,    # Hides row names for a cleaner look
  CSS = list(css.table = "width: 50%;", css.caption = "font-weight: bold; text-align: center;")
)
```


```{r , echo= FALSE, message = FALSE, warning=FALSE}
pop_vote <- read_csv("popvote_1948_2020.csv")
pop_vote1 <- pop_vote |>
  select(year,party,pv2p,incumbent_party, juneapp)|> 
  filter(party == "democrat") 
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
nat_polls <- read_csv("national_polls_1968-2024.csv")
weighted_polling <- nat_polls |>
  filter(party == "DEM") |>
  group_by(year) |>
  filter(weeks_left < 9 & weeks_left >= 5) |>
 summarize(weighted_avg_poll = mean(poll_support)) |>
  left_join(pop_vote1, by = "year") 
```


```{r , echo= FALSE, message = FALSE, warning=FALSE}
fred_econ <- read_csv("fred_econ.csv") 
fred_adjusted <- fred_econ |>
  filter(year > 1958) |>
  mutate(unemployment_growth_quarterly = (unemployment - lag(unemployment, 1)) / lag(unemployment, 1) * 100) |>
  filter(quarter == 2) |>
  mutate(RDPI_growth_annually = (RDPI - lag(RDPI, 1)) / lag(RDPI, 1) * 100) |> 
  mutate(sp500_growth_quarterly = ((sp500_adj_close - sp500_open)) / sp500_open * 100) |>
  mutate(sp500_growth_anually = (sp500_adj_close - lag(sp500_adj_close, 1)) / lag(sp500_adj_close, 1) * 100) |> 
  mutate(unemployment_growth_anually = (unemployment - lag(unemployment, 1)) / lag(unemployment, 1) * 100) |>
  filter(year >= 1960 & year != 2020 & year %% 4 == 0) |> #exclude 2020 since it such an outlier
  select(year, RDPI_growth_quarterly, GDP_growth_quarterly)

```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
model_one_data <- weighted_polling |>
  left_join(fred_adjusted, by = "year") |> 
  mutate(incumbent_party = ifelse(incumbent_party == "TRUE", 1, 0)) 
model_one_data_p <- model_one_data |> 
  filter(year > 2020)
model_one_data_r <- model_one_data |> 
  filter(year < 2020)
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
model_one <- lm(pv2p ~ weighted_avg_poll + RDPI_growth_quarterly + incumbent_party, data = model_one_data_r)

```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
pred_model_one <- predict(model_one, model_one_data_p, interval = "prediction")
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
pred_model_one_df <- as.data.frame(pred_model_one)
colnames(pred_model_one_df) <- c("Prediction", "Lower Bound", "Upper Bound")
pred_model_one_df <- data.frame( #Used ChatGPT to add % signs and use sjPLot
  Prediction = sprintf("%.2f%%", pred_model_one_df$Prediction),
  `Lower Bound` = sprintf("%.2f%%", pred_model_one_df$`Lower Bound`),
  `Upper Bound` = sprintf("%.2f%%", pred_model_one_df$`Upper Bound`)
)

lm_predictions <- predict(model_one, model_one_data_r)

lm_mse <- mean((model_one_data_r$pv2p - lm_predictions)^2)

nat_model <- tab_model(model_one, 
                       show.se = TRUE, 
                       title = paste("Linear Regression Model for Democrat Two Party Vote Share\n(In-sample MSE:", sprintf("%.4f", lm_mse), ")"),
                       dv.labels = "Democrat National Two Party Vote Share",  
                       pred.labels = c("Weighted Avg. Poll", "RDPI Growth Quarterly", "Incumbent Party"))

nat_pred <- tab_df(pred_model_one_df, 
       title = "2024 Democrat Two Party Vote Share via Linear Regression",
       show.rownames = FALSE)
```

# Introoduction
This week, most of the work focused on updating last week’s ensemble model to create weights for individual states. The adjustments were more challenging than expected, taking additional time and limiting other updates.

# National Two-Party Vote Share

This model remains the same as in previous weeks, predicting that VP Harris will win by 3.31 percentage points.
Linear State Model


```{r , echo= FALSE, message = FALSE, warning=FALSE}
nat_pred
```

# Linear Model

The primary adjustment here was adding updated polling data and removing the lagged vote share from two elections ago. I felt this change was necessary since many of the states in question (Georgia, Arizona, North Carolina) were not considered swing states in 2016, and significant demographic shifts have since altered the electorate, making the 2016 vote share an unreliable predictor for 2024. Beyond these changes, the model maintains last week’s approach, regressing over polling, fundamentals, and economic factors.

The model still predicts a win for Harris in Michigan, Nevada, Wisconsin, and Pennsylvania, though with narrower margins than last week, likely due to a tighter polling spread. This week, however, the model flips Georgia back to Trump by a razor-thin margin of 0.14 percentage points, and overall, there’s a slight shift in predicted vote shares toward Trump across all states.
Ensemble Model



```{r , echo= FALSE, message = FALSE, warning=FALSE}
lm_pred
```
# Ensemble Model

Last week’s model had a significant flaw: it used the same weights across all states instead of creating state-specific weights. I addressed this by creating a function to apply individualized weights for each state. Additionally, I realized that excluding an intercept since week four might have reduced prediction accuracy. To resolve this, I’ve reintroduced an intercept using Florida as the baseline.

The model was trained on elections up to 2016, with weights fitted to 2016 data. This week, I also added 2019 projections of economic factors to 2020 data to enhance prediction accuracy, though I kept 2020 data isolated to calculate a true out-of-sample MSE for testing accuracy.

These adjustments substantially improved the in-sample MSE, with most states now below 1. However, I suspect this improvement is due to overfitting to 2016 data rather than genuine model strength, given the high out-of-sample MSE. While states like Georgia and North Carolina appear accurate, this may be due to random chance rather than predictive accuracy.


```{r , echo= FALSE, message = FALSE, warning=FALSE}
in_MSE
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
out_MSE
```

The main issue with this model is likely due to restrictive weight constraints. Currently, the model applies a Beta between 0 and 1, preventing negative weights. This constraint may be overly limiting, as two of the regression models are often minimized to nearly zero, relying mainly on a single model. Optimizing these constraints and weights should improve predictive accuracy.

At present, the ensemble model predicts a win for Harris only in Nevada. Nearly all states have shifted towards Trump, with margins between 1.5 and 2.5 points, except North Carolina, which shows a more substantial lead for Trump at -7.06 points.


```{r , echo= FALSE, message = FALSE, warning=FALSE}
e_pred
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
map
```

