---
title: 'Post #5: State Level Predictions'
author: Avi Agarwal
date: '2024-10-07'
slug: post-5-state-level-predictions
categories: []
tags: []
---
```{r , echo= FALSE, message = FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
library(sjPlot)
library(car)
library(caret)
library(CVXR)
library(foreign)
library(glmnet)
library(haven)
library(janitor)
library(kableExtra)
library(maps)
library(mlr3)
library(randomForest)
library(ranger)
library(RColorBrewer)
library(sf)
library(viridis)
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
pop_vote <- read_csv("popvote_1948-2020.csv")
pop_vote1 <- pop_vote |>
  select(year,party,pv2p,incumbent_party, juneapp)|> 
  filter(party == "democrat") 
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
nat_polls <- read_csv("national_polls_1968-2024.csv")
weighted_polling <- nat_polls |>
  filter(party == "DEM") |>
  group_by(year) |>
  filter(weeks_left < 9 & weeks_left >= 5) |>
 summarize(weighted_avg_poll = mean(poll_support)) |>
  left_join(pop_vote1, by = "year") 
```


```{r , echo= FALSE, message = FALSE, warning=FALSE}
fred_econ <- read_csv("fred_econ.csv") 
fred_adjusted <- fred_econ |>
  filter(year > 1958) |>
  mutate(unemployment_growth_quarterly = (unemployment - lag(unemployment, 1)) / lag(unemployment, 1) * 100) |>
  filter(quarter == 2) |>
  mutate(RDPI_growth_annually = (RDPI - lag(RDPI, 1)) / lag(RDPI, 1) * 100) |> 
  mutate(sp500_growth_quarterly = ((sp500_adj_close - sp500_open)) / sp500_open * 100) |>
  mutate(sp500_growth_anually = (sp500_adj_close - lag(sp500_adj_close, 1)) / lag(sp500_adj_close, 1) * 100) |> 
  mutate(unemployment_growth_anually = (unemployment - lag(unemployment, 1)) / lag(unemployment, 1) * 100) |>
  filter(year >= 1960 & year != 2020 & year %% 4 == 0) |> #exclude 2020 since it such an outlier
  select(year, RDPI_growth_quarterly, GDP_growth_quarterly)

```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
model_one_data <- weighted_polling |>
  left_join(fred_adjusted, by = "year") |> 
  mutate(incumbent_party = ifelse(incumbent_party == "TRUE", 1, 0)) 
model_one_data_p <- model_one_data |> 
  filter(year > 2020)
model_one_data_r <- model_one_data |> 
  filter(year < 2020)
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
model_one <- lm(pv2p ~ weighted_avg_poll + RDPI_growth_quarterly + incumbent_party, data = model_one_data_r)

```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
pred_model_one <- predict(model_one, model_one_data_p, interval = "prediction")
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
pred_model_one_df <- as.data.frame(pred_model_one)
colnames(pred_model_one_df) <- c("Prediction", "Lower Bound", "Upper Bound")
pred_model_one_df <- data.frame( #Used ChatGPT to add % signs and use sjPLot
  Prediction = sprintf("%.2f%%", pred_model_one_df$Prediction),
  `Lower Bound` = sprintf("%.2f%%", pred_model_one_df$`Lower Bound`),
  `Upper Bound` = sprintf("%.2f%%", pred_model_one_df$`Upper Bound`)
)

lm_predictions <- predict(model_one, model_one_data_r)

lm_mse <- mean((model_one_data_r$pv2p - lm_predictions)^2)

nat_model <- tab_model(model_one, 
                       show.se = TRUE, 
                       title = paste("Linear Regression Model for Democrat Two Party Vote Share\n(In-sample MSE:", sprintf("%.4f", lm_mse), ")"),
                       dv.labels = "Democrat National Two Party Vote Share",  
                       pred.labels = c("Weighted Avg. Poll", "RDPI Growth Quarterly", "Incumbent Party"))

nat_pred <- tab_df(pred_model_one_df, 
       title = "2024 Democrat Two Party Vote Share via Linear Regression",
       show.rownames = FALSE)
```


```{r, echo= FALSE, message = FALSE, warning=FALSE}
rf_model_data <- weighted_polling |>
  left_join(fred_adjusted, by = "year") |> 
  mutate(incumbent_party = ifelse(incumbent_party == "TRUE", 1, 0))

rf_model_data_r <- rf_model_data |> filter(year < 2020)
rf_model_data_p <- rf_model_data |> filter(year == 2024)

train_data <- rf_model_data_r |> 
  select(pv2p, weighted_avg_poll, RDPI_growth_quarterly, incumbent_party)

predict_data <- rf_model_data_p |>
  select(weighted_avg_poll, RDPI_growth_quarterly, incumbent_party)

n_features <- ncol(train_data) - 1

rf_fit <- ranger( #Used GPT to help with rf syntax
  pv2p ~ ., 
  data = train_data, 
  mtry = floor(n_features / 3), 
  respect.unordered.factors = "order", 
  seed = 02138, 
  classification = FALSE
)

rf_predictions <- predict(rf_fit, data = predict_data)$predictions

pred_model_rf_df <- data.frame(
  year = 2024,
  Prediction = sprintf("%.2f%%", rf_predictions)
)
```

```{R}
in_sample_rf_predictions <- predict(rf_fit, data = train_data)$predictions

in_sample_mse <- mean((rf_model_data_r$pv2p - in_sample_rf_predictions)^2)

in_sample_fit_df <- data.frame(
  year = rf_model_data_r$year,
  Actual = sprintf("%.2f%%", rf_model_data_r$pv2p),
  Predicted = sprintf("%.2f%%", in_sample_rf_predictions)
)

nat_rf_in_sample_error <- tab_df(in_sample_fit_df, 
       title = paste("In-sample Fit of Democrat National Two Party Vote Share via Random Forest\n(In-sample MSE:", sprintf("%.4f", in_sample_mse), ")"),
       show.rownames = FALSE)


rf_nat_pred <- tab_df(pred_model_rf_df, 
       title = "2024 Democrat NationalTwo Party Vote Share via Random Forest Model",
       show.rownames = FALSE)
```



```{r , echo= FALSE, message = FALSE, warning=FALSE}
swing_states <- c("Arizona", "Georgia", "Michigan", "Nevada", "North Carolina", "Pennsylvania", "Wisconsin")
swing_state_polls <- read_csv("state_polls_1968-2024.csv") |>
  filter(state %in% swing_states & weeks_left < 15 & weeks_left >= 5 & party == "DEM") |>
  group_by(year, state) |>
  summarize(avg_poll_14_9 = mean(poll_support[weeks_left <= 14 & weeks_left >= 9]),
    avg_poll_8_5 = mean(poll_support[weeks_left < 9 & weeks_left >= 5]))
```

```{r, echo= FALSE, message = FALSE, warning=FALSE}
state_pop_vote <- read.csv("state_popvote_1948_2020.csv") |>
  mutate(pv2p = D_pv2p)
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
swing_model_data <- swing_state_polls |>
  left_join(fred_adjusted, by = "year") |> 
  left_join(pop_vote1, by = "year") |>
  select(-pv2p) |>
  left_join(state_pop_vote, by = c("year", "state")) |>
  mutate(incumbent_party = ifelse(incumbent_party == "TRUE", 1, 0))

```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
swing_model_data_r <- swing_model_data |> filter(year < 2020)
swing_model_data_p <- swing_model_data |> filter(year == 2024)

lm_swing_model <- lm(pv2p ~ avg_poll_8_5 + state + RDPI_growth_quarterly + incumbent_party, data = swing_model_data_r)

pred_lm_swing_model <- predict(lm_swing_model, swing_model_data_p, interval = "prediction")

```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
pred_lm_swing_model_df <- as.data.frame(pred_lm_swing_model)
colnames(pred_lm_swing_model_df) <- c("Prediction", "Lower Bound", "Upper Bound")

state_model_lm <- tab_model(lm_swing_model, 
                          show.se = TRUE,
                          title = "Linear Regresion Model for Swing States",
                          dv.labels = "Democrat Two Party Vote Share",  
                          pred.labels = c("intercept", "Avg Poll Weeks 8-5", "state", "RDPI Growth Quarterly", "Incumbent Party"))

pred_lm_swing_model_df <- data.frame(
  state = swing_model_data_p$state,
  year = 2024,
  Prediction = sprintf("%.2f%%", pred_lm_swing_model_df$Prediction),
  `Lower Bound` = sprintf("%.2f%%", pred_lm_swing_model_df$`Lower Bound`),
  `Upper Bound` = sprintf("%.2f%%", pred_lm_swing_model_df$`Upper Bound`)
)

lm_swing_pred <- tab_df(pred_lm_swing_model_df, 
       title = "2024 Democrat Two Party Vote Share via Linear Model in Swing States",
       show.rownames = FALSE)
```



```{r , echo= FALSE, message = FALSE, warning=FALSE}

swing_train_data <- swing_model_data_r |> 
  select(pv2p, state, avg_poll_8_5, RDPI_growth_quarterly, incumbent_party)

swing_predict_data <- swing_model_data_p |> 
  select(avg_poll_8_5,state, RDPI_growth_quarterly, incumbent_party)

n_swing_features <- ncol(swing_train_data) - 1

rf_swing_fit <- ranger(
  pv2p ~ ., 
  data = swing_train_data, 
  mtry = floor(n_swing_features / 3), 
  respect.unordered.factors = "order", 
  seed = 02138, 
  classification = FALSE
)

rf_swing_predictions <- predict(rf_swing_fit, data = swing_predict_data)$predictions

swing_pred_model_rf_df <- data.frame(
  state = swing_model_data_p$state,
  year = 2024,
  Prediction = sprintf("%.3f%%", rf_swing_predictions)
)

rf_swing_preds <- tab_df(swing_pred_model_rf_df, 
       title = "2024 Democrat Two Party Vote Share via Random Forest Model in Swing States",
       show.rownames = FALSE)
```

# Introduction

This week’s post builds on last week’s and introduces the structure followed in each post leading up to the election. I will develop two models to predict the national two-party popular vote and forecast the Electoral College outcome. These models will be updated with new data, such as recent polls, and enhanced with additional variables and prediction methods to fine-tune our projections.

# National Two-Party Vote Predictions

I decided to shift away from using a weighted polling average and instead focus on a simple average of polls from weeks 5 to 8. The main reason for this change is that the weighted polling average, constructed by regressing historical data on each week, resulted in an artificially high R-squared of around 0.95 when recent poll data was added. This high correlation occurred because the weighted polling average was based on the same outcome factor being regressed again, leading to a model that seemed highly accurate but was likely overfitting to past data. Such overfitting makes it a poor predictor of future election outcomes. By switching to an average of polls from weeks 5 to 8, I aim to use a more straightforward and unbiased metric, which should offer better predictive power without inflating the model’s performance through recursive correlation. I will later explain why I chose this specific period.

As a result, this week's linear regression model, which is otherwise identical to last week’s, has a lower adjusted R-squared. However, I believe this model is a better predictor for future outcomes. The share it predicts for Harris has increased to 53% which is more compared to last week, likely due to recent polling trends in her favor over Trump. I am unsure why Q2 RDPI growth is no longer statistically significant in this model. My main theory is that polls closer to the election are more strongly correlated with the actual two-party vote share, which may reduce the overall impact of Q2 RDPI growth in the model.

```{r , echo= FALSE, message = FALSE, warning=FALSE}
nat_model
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
nat_pred
```

For comparison, I also created a random forest model using the same covariates and time period but through a different methodology. The in-sample fit of the random forest model produced an MSE of around 7%, which is higher than the linear regression’s MSE of around 5%.

The random forest model also predicts a popular vote victory for Harris, but by a much smaller margin. In fact, her predicted lead of 1.63% in the popular vote suggests that losing the Electoral College could be a real possibility. To fully assess the outcome of this election, we must look more closely at individual states.


```{r  , echo= FALSE, message = FALSE, warning=FALSE}
nat_rf_in_sample_error
```

```{r , echo= FALSE, message = FALSE, warning=FALSE}
rf_nat_pred
```

# State Level Predictions

I would like to begin by discussing the states I will be covering in my predictions. As we discovered in week 1, there are only seven states that could realistically be won by either party in this election based on historical trends. This is further supported by the fact that these seven states are currently listed as toss-ups by both the Cook Political Report and Sabato’s Crystal Ball. As a result, it is impractical to predict the outcome in any other state, where the winner is almost certain. This means we are starting with Harris holding 226 electoral votes and Trump with 219 votes. The remaining 95 electoral votes are in play across Arizona, Georgia, Nevada, Pennsylvania, Wisconsin, and Michigan.

To predict the outcomes in these swing states, I built a linear regression model using polling averages, Q2 RDPI growth, the incumbent party, and state-level differentiation. The decision to focus on polling averages from weeks 8 to 5 in the national model comes from the fact that this was the smallest, most recent time frame in which every state had available polls for all elections measured from 1968 to 2016. Another choice I made was to use national RDPI growth instead of state-level data. While state-specific economic indicators could offer additional granularity, many voters tend to view the economy in national terms. Even if their state is doing well, hearing about broader economic struggles in the media may influence their perception of the national economy negatively. For this reason, I decided to stick with national Q2 RDPI growth in the model.


```{r , echo= FALSE, message = FALSE, warning=FALSE}
state_model_lm
```


This model saw Harris winning Michigan, Nevada, Wisconsin, and Pennsylvania which would push her over 270 and result in her wining the presidency. The adjusted R-squared was less that 0.5 suggesting this model does not account for much of the variance in state electionS.

```{r , echo= FALSE, message = FALSE, warning=FALSE}
lm_swing_pred
```

Similar to national two party vote, I also created a random forest model that predicted the state level outcomes. This model resulted the same state level prediction except for Arizona which flipped back to Harris by a extremely thin margin. 


```{r , echo= FALSE, message = FALSE, warning=FALSE}
rf_swing_preds
```

# Conclusion

Overall, all of my models predict a Harris victory in the Electoral College and national two party popular vote though by slim margins. I look forward to refining these models further as we get close to election day.